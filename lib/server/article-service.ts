import { createAdminClient } from "@/lib/supabase/server"
import type { ArticleInsert, ArticleUpdate, Article } from "@/lib/types/database"

export class ArticleService {
  /**
   * üîπ R√©cup√©rer la liste des articles avec filtres optionnels
   */
  static async getArticles(
    filters: {
      status?: "all" | "published" | "draft"
      category?: string
      search?: string
      limit?: number
      offset?: number
    } = {},
  ) {
    console.log("üü¢ ArticleService.getArticles - D√©but")
    console.log("üìä Filtres re√ßus:", JSON.stringify(filters, null, 2))
    
    let supabase
    try {
      supabase = await createAdminClient()
      console.log("‚úÖ Client Supabase cr√©√© avec succ√®s")
    } catch (clientError) {
      console.error("‚ùå Erreur lors de la cr√©ation du client Supabase:", clientError)
      throw new Error("Impossible de se connecter √† la base de donn√©es: " + (clientError instanceof Error ? clientError.message : String(clientError)))
    }

    try {
      // Construire la requ√™te de base
      // Exclure les ebooks directement dans la requ√™te si la colonne existe
      let articlesQuery = supabase
        .from("articles")
        .select("*")
        .order("created_at", { ascending: false })
      
      // Ne pas filtrer par is_ebook dans la requ√™te initiale
      // On filtrera c√¥t√© application apr√®s r√©cup√©ration pour plus de robustesse

      // --- Filtres ---
      if (filters.status === "published") {
        articlesQuery = articlesQuery.eq("is_published", true)
      } else if (filters.status === "draft") {
        articlesQuery = articlesQuery.eq("is_published", false)
      }

      if (filters.category && filters.category !== "all") {
        articlesQuery = articlesQuery.eq("category_id", filters.category)
      }

      // Filtre de recherche - utiliser ilike avec OR
      if (filters.search && filters.search.trim() !== "") {
        const searchTerm = filters.search.trim()
        // Syntaxe correcte pour Supabase: column.ilike.%value%
        articlesQuery = articlesQuery.or(
          `title.ilike.%${searchTerm}%,excerpt.ilike.%${searchTerm}%,content.ilike.%${searchTerm}%`
        )
      }

      // R√©cup√©rer un nombre raisonnable d'articles (max 1000 pour √©viter les probl√®mes)
      // On appliquera le filtrage des ebooks et les limites apr√®s
      const maxFetch = filters.limit ? Math.min(filters.limit * 5, 1000) : 1000
      articlesQuery = articlesQuery.limit(maxFetch)

      console.log("üîç Ex√©cution de la requ√™te Supabase...")
      const { data: articles, error: articlesError } = await articlesQuery
      
      if (articlesError) {
        console.error("‚ùå Erreur Supabase dans getArticles:")
        console.error("   Code:", articlesError.code)
        console.error("   Message:", articlesError.message)
        console.error("   D√©tails:", articlesError.details)
        console.error("   Hint:", articlesError.hint)
        throw new Error(`Erreur Supabase: ${articlesError.message} (Code: ${articlesError.code})`)
      }

      if (!articles || articles.length === 0) {
        console.log("‚ÑπÔ∏è  Aucun article trouv√© dans la base de donn√©es")
        return []
      }
      
      console.log(`üì¶ ${articles.length} articles r√©cup√©r√©s de la base de donn√©es`)
      
      // Filtrer les ebooks c√¥t√© application (plus robuste)
      // Si is_ebook existe et est true, on exclut l'article
      let filteredArticles = articles.filter((article: any) => {
        // Si is_ebook n'existe pas, est false, ou est null, c'est un article normal
        // G√©rer le cas o√π is_ebook pourrait √™tre undefined, null, false, ou true
        const isEbook = article.is_ebook === true || article.is_ebook === "true" || article.is_ebook === 1
        return !isEbook
      })
      
      console.log(`üìä ${filteredArticles.length} articles apr√®s filtrage des ebooks (${articles.length - filteredArticles.length} ebooks exclus)`)
      
      // Appliquer l'offset apr√®s filtrage
      if (filters.offset && filters.offset > 0) {
        filteredArticles = filteredArticles.slice(filters.offset)
      }
      
      // Appliquer la limite apr√®s filtrage et offset
      if (filters.limit && filteredArticles.length > filters.limit) {
        filteredArticles = filteredArticles.slice(0, filters.limit)
      }
      
      if (filteredArticles.length === 0) {
        console.log("‚ÑπÔ∏è  Aucun article trouv√© apr√®s filtrage et pagination")
        return []
      }
      
      console.log(`‚úÖ ${filteredArticles.length} articles apr√®s pagination`)

      // --- R√©cup√©ration des IDs associ√©s ---
      const authorIds = [...new Set(filteredArticles.map((a: any) => a.author_id).filter(Boolean))]
      const categoryIds = [...new Set(filteredArticles.map((a: any) => [a.category_id, a.subcategory_id]).flat().filter(Boolean))]

      // --- Auteurs ---
      let authors: any[] = []
      if (authorIds.length > 0) {
        const { data: authorsData, error: authorsError } = await supabase
          .from("users")
          .select("id, first_name, last_name, avatar_url")
          .in("id", authorIds)

        if (!authorsError) authors = authorsData || []
      }

      // --- Cat√©gories ---
      let categories: any[] = []
      if (categoryIds.length > 0) {
        const { data: categoriesData, error: categoriesError } = await supabase
          .from("article_categories")
          .select("id, name, slug, color, parent_id")
          .in("id", categoryIds)

        if (categoriesError) {
          console.error("‚ùå Erreur lors de la r√©cup√©ration des cat√©gories:", categoriesError)
        } else {
          categories = categoriesData || []
          console.log(`‚úÖ ${categories.length} cat√©gories r√©cup√©r√©es`)
        }
      }

      // --- Enrichissement des articles ---
      const enrichedArticles = filteredArticles.map((article: any) => {
        const author = authors.find((a: any) => a.id === article.author_id) || null
        const category = categories.find((c: any) => c.id === article.category_id) || null
        const subcategory = article.subcategory_id
          ? categories.find((c: any) => c.id === article.subcategory_id) || null
          : null

        // ‚úÖ Correction : garantir que tags est toujours un tableau
        const tags =
          Array.isArray(article.tags)
            ? article.tags
            : typeof article.tags === "string"
            ? article.tags.split(",").map((t: string) => t.trim()).filter(Boolean)
            : []

        return {
          ...article,
          author,
          category,
          subcategory,
          tags,
        }
      })

      console.log(`‚úÖ ${enrichedArticles.length} articles enrichis avec succ√®s`)
      return enrichedArticles
    } catch (error) {
      console.error("‚ùå Erreur dans getArticles:", error)
      if (error instanceof Error) {
        console.error("‚ùå Message d'erreur:", error.message)
        console.error("‚ùå Stack trace:", error.stack)
        throw error
      }
      throw new Error("Impossible de r√©cup√©rer les articles.")
    }
  }

  /**
   * üîπ R√©cup√©rer un article par ID
   */
  static async getArticleById(id: string) {
    const supabase = await createAdminClient()

    try {
      const { data: article, error } = await supabase
        .from("articles")
        .select("*")
        .eq("id", id)
        .single()

      if (error || !article) throw error || new Error("Article introuvable")

      const [author, category] = await Promise.all([
        article.author_id
          ? supabase
              .from("users")
              .select("id, first_name, last_name, avatar_url")
              .eq("id", article.author_id)
              .single()
              .then(res => res.data)
          : null,
        article.category_id
          ? supabase
              .from("article_categories")
              .select("id, name, slug, color")
              .eq("id", article.category_id)
              .single()
              .then(res => res.data)
          : null,
      ])

      const tags =
        Array.isArray(article.tags)
          ? article.tags
          : typeof article.tags === "string"
          ? article.tags.split(",").map(t => t.trim()).filter(Boolean)
          : []

      return { ...article, author, category, tags }
    } catch (error) {
      console.error("‚ùå Erreur dans getArticleById:", error)
      throw new Error("Impossible de r√©cup√©rer l‚Äôarticle.")
    }
  }

  /**
   * üîπ R√©cup√©rer un article par son slug
   */
  static async getArticleBySlug(slug: string) {
    const supabase = await createAdminClient()

    try {
      const { data: article, error } = await supabase
        .from("articles")
        .select("*")
        .eq("slug", slug)
        .eq("is_published", true)
        .single()

      if (error || !article) throw error || new Error("Article introuvable")

      const [author, category] = await Promise.all([
        article.author_id
          ? supabase
              .from("users")
              .select("id, first_name, last_name, avatar_url")
              .eq("id", article.author_id)
              .single()
              .then(res => res.data)
          : null,
        article.category_id
          ? supabase
              .from("article_categories")
              .select("id, name, slug, color")
              .eq("id", article.category_id)
              .single()
              .then(res => res.data)
          : null,
      ])

      const tags =
        Array.isArray(article.tags)
          ? article.tags
          : typeof article.tags === "string"
          ? article.tags.split(",").map(t => t.trim()).filter(Boolean)
          : []

      return { ...article, author, category, tags }
    } catch (error) {
      console.error("‚ùå Erreur dans getArticleBySlug:", error)
      throw new Error("Impossible de r√©cup√©rer l‚Äôarticle.")
    }
  }

  /**
   * üîπ R√©cup√©rer des articles li√©s
   */
  static async getRelatedArticles(currentArticleId: string, categoryId: string, limit: number = 3) {
    const supabase = await createAdminClient()

    try {
      const { data: articles, error } = await supabase
        .from("articles")
        .select("*")
        .eq("category_id", categoryId)
        .eq("is_published", true)
        .neq("id", currentArticleId)
        .order("created_at", { ascending: false })
        .limit(limit)

      if (error) throw error
      if (!articles || articles.length === 0) return []

      const { data: categories } = await supabase
        .from("article_categories")
        .select("id, name, slug, color")
        .in("id", [categoryId])

      return articles.map(article => {
        const category = categories?.find(c => c.id === article.category_id) || null
        const tags =
          Array.isArray(article.tags)
            ? article.tags
            : typeof article.tags === "string"
            ? article.tags.split(",").map(t => t.trim()).filter(Boolean)
            : []
        return { ...article, category, tags }
      })
    } catch (error) {
      console.error("‚ùå Erreur dans getRelatedArticles:", error)
      throw new Error("Impossible de r√©cup√©rer les articles li√©s.")
    }
  }

  /**
   * üîπ Cr√©er un article
   */
  static async createArticle(articleData: ArticleInsert) {
    const supabase = await createAdminClient()

    try {
      const slug = this.generateSlug(articleData.title)
      const { data, error } = await supabase
        .from("articles")
        .insert({
          ...articleData,
          slug,
          created_at: new Date().toISOString(),
          updated_at: new Date().toISOString(),
        })
        .select("*")
        .single()

      if (error) throw error
      return data
    } catch (error) {
      console.error("‚ùå Erreur dans createArticle:", error)
      throw new Error("Impossible de cr√©er l‚Äôarticle.")
    }
  }

  /**
   * üîπ Mettre √† jour un article
   */
  static async updateArticle(id: string, articleData: ArticleUpdate) {
    const supabase = await createAdminClient()

    try {
      const updateData = {
        ...articleData,
        updated_at: new Date().toISOString(),
      }

      if (articleData.title) {
        updateData.slug = this.generateSlug(articleData.title)
      }

      const { data, error } = await supabase
        .from("articles")
        .update(updateData)
        .eq("id", id)
        .select("*")
        .single()

      if (error) throw error
      return data
    } catch (error) {
      console.error("‚ùå Erreur dans updateArticle:", error)
      throw new Error("Impossible de mettre √† jour l‚Äôarticle.")
    }
  }

  /**
   * üîπ Supprimer un article
   */
  static async deleteArticle(id: string) {
    const supabase = await createAdminClient()
    try {
      const { error } = await supabase.from("articles").delete().eq("id", id)
      if (error) throw error
      return true
    } catch (error) {
      console.error("‚ùå Erreur dans deleteArticle:", error)
      throw new Error("Impossible de supprimer l‚Äôarticle.")
    }
  }

  /**
   * üîπ R√©cup√©rer les ebooks avec filtres optionnels
   */
  static async getEbooks(
    filters: {
      category?: string
      search?: string
      limit?: number
      offset?: number
      publishedOnly?: boolean
    } = {},
  ) {
    console.log("üü¢ ArticleService.getEbooks - D√©but")
    console.log("üìä Filtres re√ßus:", JSON.stringify(filters, null, 2))
    
    let supabase
    try {
      supabase = await createAdminClient()
      console.log("‚úÖ Client Supabase cr√©√© avec succ√®s")
    } catch (clientError) {
      console.error("‚ùå Erreur lors de la cr√©ation du client Supabase:", clientError)
      throw new Error("Impossible de se connecter √† la base de donn√©es: " + (clientError instanceof Error ? clientError.message : String(clientError)))
    }

    try {
      // Construire la requ√™te de base pour les ebooks
      // Note: On accepte les ebooks avec ou sans prix (pour le dashboard admin)
      let ebooksQuery = supabase
        .from("articles")
        .select("*")
        .order("created_at", { ascending: false })

      // Essayer de filtrer par is_ebook si la colonne existe
      // Sinon, on retournera un tableau vide
      try {
        ebooksQuery = ebooksQuery.eq("is_ebook", true)
      } catch (e) {
        // Si la colonne n'existe pas, retourner un tableau vide
        console.log("‚ÑπÔ∏è  Colonne is_ebook non disponible, aucun ebook trouv√©")
        return []
      }

      // Filters
      if (filters.publishedOnly === true) {
        ebooksQuery = ebooksQuery.eq("is_published", true)
      } else if (filters.publishedOnly === false) {
        // Pour le dashboard admin, on peut inclure tous les ebooks
        // Ne pas filtrer par is_published
      }
      // Si publishedOnly est undefined, ne pas filtrer (comportement par d√©faut pour admin)

      if (filters.category && filters.category !== "all" && filters.category !== "") {
        ebooksQuery = ebooksQuery.eq("category_id", filters.category)
      }

      if (filters.search && filters.search.trim() !== "") {
        const searchTerm = filters.search.trim()
        ebooksQuery = ebooksQuery.or(
          `title.ilike.%${searchTerm}%,excerpt.ilike.%${searchTerm}%,content.ilike.%${searchTerm}%`,
        )
      }

      // R√©cup√©rer un nombre raisonnable d'ebooks (max 1000)
      const maxFetch = filters.limit ? Math.min(filters.limit * 5, 1000) : 1000
      ebooksQuery = ebooksQuery.limit(maxFetch)

      console.log("üîç Ex√©cution de la requ√™te Supabase pour les ebooks...")
      const { data: ebooks, error: ebooksError } = await ebooksQuery
      
      if (ebooksError) {
        // Si l'erreur est li√©e √† la colonne is_ebook qui n'existe pas, retourner un tableau vide
        if (ebooksError.message && (ebooksError.message.includes("is_ebook") || ebooksError.message.includes("column") || ebooksError.code === "42703")) {
          console.log("‚ÑπÔ∏è  Colonne is_ebook non disponible dans la base de donn√©es, aucun ebook trouv√©")
          return []
        }
        
        console.error("‚ùå Erreur Supabase dans getEbooks:")
        console.error("   Code:", ebooksError.code)
        console.error("   Message:", ebooksError.message)
        console.error("   D√©tails:", ebooksError.details)
        console.error("   Hint:", ebooksError.hint)
        throw new Error(`Erreur Supabase: ${ebooksError.message} (Code: ${ebooksError.code})`)
      }

      if (!ebooks || ebooks.length === 0) {
        console.log("‚ÑπÔ∏è  Aucun ebook trouv√© dans la base de donn√©es")
        return []
      }
      
      console.log(`üì¶ ${ebooks.length} ebooks r√©cup√©r√©s de la base de donn√©es`)

      // Appliquer l'offset apr√®s r√©cup√©ration
      let filteredEbooks = ebooks
      if (filters.offset && filters.offset > 0) {
        filteredEbooks = filteredEbooks.slice(filters.offset)
      }
      
      // Appliquer la limite apr√®s offset
      if (filters.limit && filteredEbooks.length > filters.limit) {
        filteredEbooks = filteredEbooks.slice(0, filters.limit)
      }

      if (filteredEbooks.length === 0) {
        console.log("‚ÑπÔ∏è  Aucun ebook trouv√© apr√®s pagination")
        return []
      }

      console.log(`‚úÖ ${filteredEbooks.length} ebooks apr√®s pagination`)

      // Fetch associated IDs
      const authorIds = [...new Set(filteredEbooks.map((e: any) => e.author_id).filter(Boolean))]
      const categoryIds = [...new Set(filteredEbooks.map((e: any) => [e.category_id, e.subcategory_id]).flat().filter(Boolean))]

      // Fetch authors
      let authors: any[] = []
      if (authorIds.length > 0) {
        const { data: authorsData, error: authorsError } = await supabase
          .from("users")
          .select("id, first_name, last_name, avatar_url")
          .in("id", authorIds)

        if (authorsError) {
          console.warn("‚ö†Ô∏è Erreur lors de la r√©cup√©ration des auteurs:", authorsError.message)
        } else {
          authors = authorsData || []
        }
      }

      // Fetch categories and subcategories
      let categories: any[] = []
      if (categoryIds.length > 0) {
        const { data: categoriesData, error: categoriesError } = await supabase
          .from("article_categories")
          .select("id, name, slug, color, parent_id")
          .in("id", categoryIds)

        if (categoriesError) {
          console.warn("‚ö†Ô∏è Erreur lors de la r√©cup√©ration des cat√©gories:", categoriesError.message)
        } else {
          categories = categoriesData || []
        }
      }

      // Enrich ebooks
      const enrichedEbooks = filteredEbooks.map((ebook: any) => {
        const author = authors.find((a: any) => a.id === ebook.author_id) || null
        const category = categories.find((c: any) => c.id === ebook.category_id) || null
        const subcategory = ebook.subcategory_id
          ? categories.find((c: any) => c.id === ebook.subcategory_id) || null
          : null

        return {
          ...ebook,
          author,
          category,
          subcategory,
        }
      })

      console.log(`‚úÖ ${enrichedEbooks.length} ebooks enrichis retourn√©s`)
      return enrichedEbooks
    } catch (error) {
      console.error("‚ùå Erreur dans getEbooks:", error)
      if (error instanceof Error) {
        throw error
      }
      throw new Error("Impossible de r√©cup√©rer les ebooks.")
    }
  }

  /**
   * üîπ R√©cup√©rer toutes les cat√©gories actives
   */
  static async getCategories() {
    const supabase = await createAdminClient()

    try {
      const { data, error } = await supabase
        .from("article_categories")
        .select("*")
        .eq("is_active", true)
        .order("sort_order", { ascending: true })

      if (error) throw error
      return data || []
    } catch (error) {
      console.error("‚ùå Erreur dans getCategories:", error)
      throw new Error("Impossible de r√©cup√©rer les cat√©gories.")
    }
  }

  /**
   * üîπ Incr√©menter le compteur de vues
   */
  static async incrementViewCount(id: string) {
    const supabase = await createAdminClient()
    try {
      const { error } = await supabase.rpc("increment_article_views", { article_id: id })
      if (error) console.warn("‚ö†Ô∏è Erreur de compteur:", error)
    } catch (error) {
      console.warn("‚ö†Ô∏è incrementViewCount non critique:", error)
    }
  }

  /**
   * üîπ G√©n√©rer un slug √† partir du titre
   */
  private static generateSlug(title: string): string {
    return title
      .toLowerCase()
      .normalize("NFD")
      .replace(/[\u0300-\u036f]/g, "")
      .replace(/[^a-z0-9\s-]/g, "")
      .replace(/\s+/g, "-")
      .replace(/-+/g, "-")
      .trim()
  }
}

// ‚úÖ Exports pour compatibilit√©
export const getArticles = ArticleService.getArticles
export const getArticleById = ArticleService.getArticleById
export const getArticleBySlug = ArticleService.getArticleBySlug
export const getRelatedArticles = ArticleService.getRelatedArticles
export const createArticle = ArticleService.createArticle
export const updateArticle = ArticleService.updateArticle
export const deleteArticle = ArticleService.deleteArticle
export const getCategories = ArticleService.getCategories
export const incrementViewCount = ArticleService.incrementViewCount

export type { Article }
